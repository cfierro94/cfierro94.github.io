I"q<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<p><a href="https://arxiv.org/pdf/2010.10866.pdf">LINK TO THE PAPER</a></p>

<blockquote>
  <p>Using Reinforcement Learning optimizing the <a href="https://arxiv.org/pdf/1906.01081.pdf">PARENT metric</a> leads to less omissions and hallucinations.</p>
</blockquote>

<h2 id="main-idea">Main idea</h2>
<p>They state that the data contains these two problems (hallucinations and omissions): (1) the target text contains elements that are not grounded in the structured data (due to automatic creation of the datasets), and (2) some datasets expect the text to use all table fields and others to only contain some. So if we train the model by maximizing likelihood, weâ€™re forcing it to mimic the human behaviour and thus to mimic these dataset failures/inconsistencies.</p>

<p>They achieve SOTA in PARENT scores on WebNLG and WikiBio (with BLEU scores on par with previous SOTA).</p>

<h2 id="related-work">Related work</h2>
<p><a href="https://www.aclweb.org/anthology/W19-8652.pdf">Dusek et al. (2019)</a> showed that cleaned data can significantly improve system ability to produce fact-accurate text.</p>

<h2 id="parent-score">PARENT score</h2>
<p>PARENT := <strong>P</strong>recision <strong>A</strong>nd <strong>R</strong>ecall of <strong>E</strong>ntailed <strong>N</strong>grams from the <strong>T</strong>able.</p>

<h4 id="d2t-task-definition">D2T task definition</h4>
<p>Given a table \(T = \{r_k\}_{k=1}^K\) with records \(r=(\text{entity, attribute, value})\) we want to generate a text \(G\) that summarizes the table. We will evaluate \(G\) by comparing it to a reference text \(R\). Thus, a set of tables to evaluate is the set \(D_M=\{T^i,G^i,R^i\}_{i=1}^N\).</p>

<h1 class="post-thoughts"><span>Questions/Thoughts</span></h1>
<ul>
  <li>Why?</li>
</ul>
:ET